{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib as grin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.utils import numpy_metrics\n",
    "from lib.utils.parser_utils import str_to_bool\n",
    "\n",
    "metrics = {\n",
    "    'mae': numpy_metrics.masked_mae,\n",
    "    'mse': numpy_metrics.masked_mse,\n",
    "    'mre': numpy_metrics.masked_mre,\n",
    "    'mape': numpy_metrics.masked_mape\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "122 / 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_air = pd.HDFStore('/home/jhzhou/repos/tourism-imputation/data/grin-data/air_quality/small36.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air.groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air['eval_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path('../../data/open-data/HK2012-2018/')\n",
    "df_au = pd.read_csv(data_path / 'Australia.csv')\n",
    "df_au['date'] = pd.to_datetime(df_au['date'])\n",
    "df_au.set_index('date', inplace=True)\n",
    "df_au.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lib as grin\n",
    "from lib.datasets.pd_dataset import PandasDataset\n",
    "from lib.utils import compute_mean\n",
    "dataset_path = '../../data/open-data/HK2012-2018/Australia.csv'\n",
    "mask_path = '../../data/masks/block5.npy'\n",
    "\n",
    "country = 'au'\n",
    "\n",
    "class ArrivalDataset(PandasDataset):\n",
    "    SEED = 1145\n",
    "    \n",
    "    def __init__(self, impute_nans=True, small=False, freq='MS'):\n",
    "        self.random = np.random.default_rng(self.SEED)\n",
    "        self.eval_mask = None\n",
    "        df, mask = self.load(impute_nans=impute_nans, small=small)\n",
    "        df = df.astype('float32')\n",
    "        super().__init__(dataframe=df, u=None, mask=mask, name='arrival', freq=freq, aggr='nearest')\n",
    "\n",
    "    def load_raw(self, small=False):\n",
    "        df = pd.read_csv(dataset_path, index_col=0, parse_dates=True)\n",
    "        mask = np.load(mask_path)\n",
    "        return df, mask\n",
    "\n",
    "\n",
    "    def load(self, impute_nans=True, small=False):\n",
    "        # load readings and stations metadata\n",
    "        df, eval_mask = self.load_raw(small)\n",
    "        # compute the masks\n",
    "        mask = (~np.isnan(df.values)).astype('uint8')  # 1 if value is not nan else 0\n",
    "\n",
    "        eval_mask = eval_mask.astype('uint8')\n",
    "        self.eval_mask = eval_mask  # 1 if value is ground-truth for imputation else 0\n",
    "        # eventually replace nans with weekly mean by hour\n",
    "        if impute_nans:\n",
    "            df = df.fillna(compute_mean(df))\n",
    "        # compute distances from latitude and longitude degrees\n",
    "        return df, mask\n",
    "\n",
    "    def splitter(self, dataset, val_len=1., in_sample=False, window=0):\n",
    "        if in_sample:\n",
    "            train_idxs = np.arange(len(dataset))\n",
    "        else:\n",
    "            val_len = 12\n",
    "            test_len = 24\n",
    "            train_idxs = np.arange(len(dataset) - val_len - test_len)\n",
    "            val_idxs = np.arange(len(train_idxs), len(dataset) - test_len)\n",
    "            test_idxs = np.arange(len(dataset) - test_len, len(dataset))\n",
    "        return [train_idxs, val_idxs, test_idxs]\n",
    "\n",
    "    def get_similarity(self):\n",
    "        N = len(self.df)\n",
    "        return np.ones(N, N) - np.identity(N) \n",
    "\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return self._mask\n",
    "\n",
    "    @property\n",
    "    def training_mask(self):\n",
    "        return self._mask if self.eval_mask is None else (self._mask & (1 - self.eval_mask))\n",
    "\n",
    "    def test_interval_mask(self, dtype=bool, squeeze=True):\n",
    "        m = np.in1d(self.df.index.month, self.test_months).astype(dtype)\n",
    "        if squeeze:\n",
    "            return m\n",
    "        return m[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrival = ArrivalDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.datasets import AirQuality\n",
    "air = AirQuality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrival.numpy().dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitter Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.data.imputation_dataset import ImputationDataset, GraphImputationDataset\n",
    "from lib.nn import models\n",
    "from lib import fillers, datasets, config\n",
    "\n",
    "def has_graph_support(model_cls):\n",
    "    return model_cls in [models.GRINet, models.MPGRUNet, models.BiMPGRUNet]\n",
    "model_cls, filler_cls = models.GRINet, fillers.GraphFiller\n",
    "dataset_cls = GraphImputationDataset if has_graph_support(model_cls) else ImputationDataset\n",
    "torch_dataset = dataset_cls(*dataset.numpy(return_idx=True),\n",
    "                            mask=dataset.training_mask,\n",
    "                            eval_mask=dataset.eval_mask,\n",
    "                            window=12,\n",
    "                            stride=1)\n",
    "\n",
    "idxs = dataset.splitter(torch_dataset, val_len=0.1, in_sample=False, window=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_dataset[0][0]['x'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_dataset.data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib as grin\n",
    "from lib.utils import sample_mask\n",
    "import pandas as pd\n",
    "\n",
    "arrival = pd.read_csv('/home/jhzhou/repos/tourism-imputation/data/open-data/HK2012-2018/Australia.csv', index_col=0, parse_dates=True)\n",
    "shape = arrival.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random5 = sample_mask(shape,p = 0.05, min_seq=1, max_seq=1)\n",
    "random10 = sample_mask(shape,p = 0.10, min_seq=1, max_seq=1)\n",
    "block5 = sample_mask(shape,p = 0.006, min_seq =6, max_seq=12)\n",
    "block10 = sample_mask(shape,p = 0.012, min_seq=6, max_seq=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('../../data/masks/random5.npy',random5)\n",
    "np.save('../../data/masks/random10.npy',random10)\n",
    "np.save('../../data/masks/block5.npy',block5)\n",
    "np.save('../../data/masks/block10.npy',block10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tourism-imputation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
